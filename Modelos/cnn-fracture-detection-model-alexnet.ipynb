{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4507366,"sourceType":"datasetVersion","datasetId":2634341}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## CNN para previsão de fraturas","metadata":{}},{"cell_type":"markdown","source":"**Acerca do Dataset**\n- Este conjunto de dados é composto por imagens de raios X fraturadas e não fraturadas de várias articulações. A tarefa é construir um classificador de imagens para detectar fraturas em determinada imagem de raio-X. Este conjunto de dados é composto por diferentes articulações nas extremidades superiores. O isolamento de articulações individuais é recomendado para melhorar o desempenho dos classificadores.\n- 8863 instâncias para treino\n- 600 instâncias para teste","metadata":{}},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"!pip install livelossplot","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:34:02.616079Z","iopub.execute_input":"2024-04-22T22:34:02.616449Z","iopub.status.idle":"2024-04-22T22:34:19.297205Z","shell.execute_reply.started":"2024-04-22T22:34:02.616418Z","shell.execute_reply":"2024-04-22T22:34:19.295767Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting livelossplot\n  Downloading livelossplot-0.5.5-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from livelossplot) (3.7.5)\nRequirement already satisfied: bokeh in /opt/conda/lib/python3.10/site-packages (from livelossplot) (3.4.1)\nRequirement already satisfied: Jinja2>=2.9 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (3.1.2)\nRequirement already satisfied: contourpy>=1.2 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (1.2.0)\nRequirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (1.26.4)\nRequirement already satisfied: packaging>=16.8 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (21.3)\nRequirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (2.2.2)\nRequirement already satisfied: pillow>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (9.5.0)\nRequirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (6.0.1)\nRequirement already satisfied: tornado>=6.2 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (6.3.3)\nRequirement already satisfied: xyzservices>=2021.09.1 in /opt/conda/lib/python3.10/site-packages (from bokeh->livelossplot) (2024.4.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->livelossplot) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->livelossplot) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->livelossplot) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->livelossplot) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->livelossplot) (2.9.0.post0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.1.3)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->bokeh->livelossplot) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->bokeh->livelossplot) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\nDownloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\nInstalling collected packages: livelossplot\nSuccessfully installed livelossplot-0.5.5\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport time\n\nfrom livelossplot import PlotLosses\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import SubsetRandomSampler\n\nfrom torchvision.datasets import ImageFolder\n\nfrom torchvision.models import alexnet\n\nfrom torchvision.transforms import Compose\nfrom torchvision.transforms import ToTensor\nfrom torchvision.transforms import Normalize\nfrom torchvision.transforms import Resize","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:34:19.299953Z","iopub.execute_input":"2024-04-22T22:34:19.300369Z","iopub.status.idle":"2024-04-22T22:34:26.964852Z","shell.execute_reply.started":"2024-04-22T22:34:19.300336Z","shell.execute_reply":"2024-04-22T22:34:26.963788Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### 0. Preparar o Setup","metadata":{}},{"cell_type":"code","source":"PATH_TRAIN = '/kaggle/input/bone-fracture-detection-using-xrays/archive (6)/train'\nPATH_TEST = '/kaggle/input/bone-fracture-detection-using-xrays/archive (6)/val'\n\nBATCH_SIZE = 32","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:34:26.966189Z","iopub.execute_input":"2024-04-22T22:34:26.966984Z","iopub.status.idle":"2024-04-22T22:34:26.972277Z","shell.execute_reply.started":"2024-04-22T22:34:26.966949Z","shell.execute_reply":"2024-04-22T22:34:26.971064Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:34:26.975463Z","iopub.execute_input":"2024-04-22T22:34:26.975858Z","iopub.status.idle":"2024-04-22T22:34:26.989304Z","shell.execute_reply.started":"2024-04-22T22:34:26.975826Z","shell.execute_reply":"2024-04-22T22:34:26.987868Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 1. Preparar os dados","metadata":{}},{"cell_type":"code","source":"transform = Compose(\n        [ToTensor(),\n         Resize((224, 224),antialias=True),\n         Normalize(mean=(0.1307,), std=(0.3081,))  # Normaliza as imagens\n        ])","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:34:26.991016Z","iopub.execute_input":"2024-04-22T22:34:26.991713Z","iopub.status.idle":"2024-04-22T22:34:27.000179Z","shell.execute_reply.started":"2024-04-22T22:34:26.991663Z","shell.execute_reply":"2024-04-22T22:34:26.999348Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Definir a seed\n\nseed = 2024\n\ntorch.manual_seed(seed)\nnp.random.seed(seed)\n\n# Importar dataset\ntrain_dataset = ImageFolder(PATH_TRAIN, transform=transform)\ntest_dataset = ImageFolder(PATH_TEST, transform=transform)\n\nvalidation_split = 0.2\ndataset_size = len(train_dataset)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\n\nnp.random.shuffle(indices)\n\ntrain_indices, val_indices = indices[split:], indices[:split]\n\ntrain_sampler = SubsetRandomSampler(train_indices)\nval_sampler = SubsetRandomSampler(val_indices)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)\nval_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=val_sampler)\ntest_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:34:27.001605Z","iopub.execute_input":"2024-04-22T22:34:27.001944Z","iopub.status.idle":"2024-04-22T22:34:39.034486Z","shell.execute_reply.started":"2024-04-22T22:34:27.001910Z","shell.execute_reply":"2024-04-22T22:34:39.033239Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### 2. Definir o Modelo","metadata":{}},{"cell_type":"code","source":"M_alexnet = alexnet()\n\nnum_classes = len(train_dataset.classes)\nM_alexnet.classifier[6] = torch.nn.Linear(4096, num_classes) # alteração na camada de saída","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:34:39.035831Z","iopub.execute_input":"2024-04-22T22:34:39.036171Z","iopub.status.idle":"2024-04-22T22:34:39.793675Z","shell.execute_reply.started":"2024-04-22T22:34:39.036142Z","shell.execute_reply":"2024-04-22T22:34:39.792642Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"M_alexnet.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:34:39.795125Z","iopub.execute_input":"2024-04-22T22:34:39.795988Z","iopub.status.idle":"2024-04-22T22:34:39.814794Z","shell.execute_reply.started":"2024-04-22T22:34:39.795956Z","shell.execute_reply":"2024-04-22T22:34:39.813336Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# função de perda e otimizador\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(M_alexnet.parameters(), lr=0.005, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:34:39.816211Z","iopub.execute_input":"2024-04-22T22:34:39.816547Z","iopub.status.idle":"2024-04-22T22:34:39.822809Z","shell.execute_reply.started":"2024-04-22T22:34:39.816520Z","shell.execute_reply":"2024-04-22T22:34:39.821727Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### 3. Treinar o Modelo","metadata":{}},{"cell_type":"code","source":"EPOCHS = 15\n\ndef train_model(train_dl, val_dl, model, criterion, optimizer):\n    liveloss = PlotLosses()\n    for epoch in range(EPOCHS):\n        logs = {}\n        model.train()\n        running_loss = 0.0\n        running_corrects = 0.0\n        for inputs, labels in train_dl:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.detach() * inputs.size(0)\n            _, preds = torch.max(outputs, 1)\n            running_corrects += torch.sum(preds == labels.data)\n        epoch_loss = running_loss / len(train_dl.dataset)\n        epoch_acc = running_corrects.float()/len(train_dl.dataset)\n        logs['loss'] = epoch_loss.item()\n        logs['accuracy'] = epoch_acc.item()\n        model.eval()\n        running_loss = 0.0\n        running_corrects = 0.0\n        for inputs, labels in val_dl:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_loss += loss.detach() * inputs.size(0)\n            _, preds = torch.max(outputs, 1)\n            running_corrects += torch.sum(preds == labels.data)\n        epoch_loss = running_loss / len(val_dl.dataset)\n        epoch_acc = running_corrects.float() / len(val_dl.dataset)\n        logs['val_loss'] = epoch_loss.item()\n        logs['val_accuracy'] = epoch_acc.item()\n        liveloss.update(logs)\n        liveloss.send()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:34:39.828209Z","iopub.execute_input":"2024-04-22T22:34:39.828655Z","iopub.status.idle":"2024-04-22T22:34:39.842389Z","shell.execute_reply.started":"2024-04-22T22:34:39.828623Z","shell.execute_reply":"2024-04-22T22:34:39.841581Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\n\ntrain_model(train_loader, val_loader, M_alexnet, criterion, optimizer)\n    \nend_time = time.time()\nelapsed_time = end_time - start_time\nprint(f\"\\nTraining completed in {elapsed_time} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-04-22T22:34:39.843569Z","iopub.execute_input":"2024-04-22T22:34:39.844725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Avaliar o modelo","metadata":{}},{"cell_type":"code","source":"def evaluate_model(test_dl, model):\n    predictions = list()\n    actual_values = list()\n    device = next(model.parameters()).device\n    \n    model.eval()  # Garantir que o modelo está no modo de avaliação\n    \n    with torch.no_grad():  # Desativar o cálculo de gradientes durante a avaliação\n        for inputs, labels in test_dl:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            yprev = model(inputs)\n            yprev = yprev.detach().cpu().numpy()\n            actual = labels.cpu().numpy()\n            yprev = np.argmax(yprev, axis=1)\n            actual = actual.reshape((len(actual), 1))\n            yprev = yprev.reshape((len(yprev), 1))\n            predictions.append(yprev)\n            actual_values.append(actual)\n            \n    predictions = np.vstack(predictions)\n    actual_values = np.vstack(actual_values)\n    \n    return actual_values, predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_predictions(actual_values, predictions):\n    acertou = 0\n    falhou = 0\n    primeiros = 0\n    for r, p in zip(actual_values, predictions):\n        if primeiros < 20:\n            print(f'real:{r} previsão:{p}')\n            primeiros += 1\n        if r == p:\n            acertou += 1\n        else:\n            falhou += 1\n    \n    acc = accuracy_score(actual_values, predictions)\n    print(f'Accuracy: {acc:0.3f}\\n')\n    print(f'acertou:{acertou} falhou:{falhou}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_confusion_matrix(cm, list_classes):\n    plt.figure(figsize=(16, 8))\n    sns.heatmap(cm, annot=True, xticklabels=list_classes, yticklabels=list_classes, annot_kws={\"size\": 12},\n                fmt='g', linewidths=.5)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"actual_values, predictions = evaluate_model(test_loader, M_alexnet)\ndisplay_predictions(actual_values, predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(actual_values, predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cr =classification_report(actual_values, predictions, output_dict=True)\nlist_classes=['fratured', 'not fractured']\ncm = confusion_matrix(actual_values, predictions)\nprint (cm)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_confusion_matrix(cm,list_classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}